{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kWIuwKG2_oWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634fb2d3-4d9b-4872-8609-7e00b5ee7481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "Uploading: /gdrive/.shortcut-targets-by-id/1T60SWuQWx22DjUE2yp_e4zuRrHjDucUf/output_scene_FR_0.mp4\n",
            "Uploading: /gdrive/.shortcut-targets-by-id/1nkKg-unFmfnLmZPHLG0_kxD5j1k7btAk/output_scene_FR_2.mp4\n",
            "Uploading: /gdrive/.shortcut-targets-by-id/1Qp9om3-hr-_gJCvGtcGRfKqOFO1y4C3p/output_scene_FR_3.mp4\n",
            "Uploading: /gdrive/.shortcut-targets-by-id/1e41tyrU8A_JAEdpdAFUYf_kT2oeKqWGJ/1.mp4\n",
            "Uploading: /gdrive/.shortcut-targets-by-id/1FedMVUEiAEjD9u0O8aYivU_nzm7DvAFZ/2.mp4\n",
            "[\n",
            "    {\n",
            "        \"role\": \"model\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"file_data\": {\n",
            "                    \"mime_type\": \"video/mp4\",\n",
            "                    \"file_uri\": \"https://generativelanguage.googleapis.com/v1beta/files/7hpd6qsti6ho\"\n",
            "                }\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"I want you based on these conditions (the objects that cause a change in the speed or car's direction, the objects proximity to the car, and the objects that will cause the car to stop immediately) to JUST produce a Json file that contains the object and whether it is harmful or harmless to my car\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"model\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"Here's a JSON representation of the objects detected in the video, categorized as harmful or harmless based on the provided criteria.  Note that this analysis is based on a short video clip and a limited understanding of the context. A complete autonomous driving system would require far more sophisticated analysis.  The determination of \\\\\\\"harmful\\\\\\\" is also subjective and depends on the driving scenario and speed.\\\\n\\\\n\\\\n```json\\\\n{\\\\n  \\\\\\\"objects\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Vehicle (various)\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Potential collision if not appropriately navigated, proximity varies.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Construction Cones\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Obstacle requiring avoidance to prevent collision.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Construction Equipment\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Large obstacle; immediate stop required if in close proximity.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Pedestrian (partially visible)\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Potential collision if not properly avoided.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Trees/Landscaping\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Not an immediate hazard, though could be indirectly involved in an accident.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Buildings\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Static objects; no immediate hazard.\\\\\\\"\\\\n    }\\\\n  ]\\\\n}\\\\n```\\\\n\\\\n**Important Considerations:**\\\\n\\\\n* **Incomplete Information:** The video provides only limited views of the surroundings. A real-world system would need a 360-degree view, depth sensors, and more advanced algorithms.\\\\n* **Context is Key:** The determination of \\\\\\\"harmful\\\\\\\" is highly dependent on the speed of the car, the trajectory of other objects, and overall driving conditions.\\\\n* **Dynamic Situations:** The judgment of harmful vs harmless is highly time-sensitive.  Objects can quickly become dangerous depending on their movement.\\\\n\\\\nThis JSON aims to illustrate a basic structure for representing object detection and hazard assessment. A real-world application requires far more comprehensive capabilities.\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"file_data\": {\n",
            "                    \"mime_type\": \"video/mp4\",\n",
            "                    \"file_uri\": \"https://generativelanguage.googleapis.com/v1beta/files/z5pmaqpax53w\"\n",
            "                }\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"and this\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"model\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"Here's a JSON file representing the objects detected in the new video, categorized as harmful or harmless.  Remember that this is a simplified analysis based on a short clip and limited contextual information. A real autonomous driving system would require far more sophisticated processing.\\\\n\\\\n\\\\n```json\\\\n{\\\\n  \\\\\\\"objects\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Pedestrians\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Potential collision if the vehicle does not stop or slow down appropriately.  High risk given they are crossing the street.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Vehicles (Bus, Car)\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Potential collision if not properly navigated, especially given the intersection.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Traffic Signals (Red Light)\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Requires immediate stop to avoid collision and traffic violation.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Buildings\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Static objects; no immediate hazard.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Construction (in background)\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Distant and not directly impeding the vehicle's path.\\\\\\\"\\\\n    }\\\\n  ]\\\\n}\\\\n```\\\\n\\\\n**Key Considerations:**\\\\n\\\\n* **Traffic Signals:** The red light is the most critical element.  Failure to stop poses a severe risk.\\\\n* **Pedestrian Priority:** Pedestrians in crosswalks have the right of way, making them high-risk objects.\\\\n* **Intersection Dynamics:** Intersections are inherently dangerous due to multiple moving vehicles and pedestrians.\\\\n* **Contextual Limitations:**  This analysis is very basic.  A production-ready system needs much more information (speed, distances, vehicle trajectories, etc.).\\\\n\\\\n\\\\nThis JSON should be viewed as a simplified example.  Robust object detection and hazard assessment for autonomous driving requires advanced sensor fusion, machine learning, and extensive safety protocols.\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"file_data\": {\n",
            "                    \"mime_type\": \"video/mp4\",\n",
            "                    \"file_uri\": \"https://generativelanguage.googleapis.com/v1beta/files/lkprd9tfl9ra\"\n",
            "                }\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"and this\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"model\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"Here's a JSON representation of the objects in this video clip, categorized as harmful or harmless.  Remember the caveats from previous responses: this is a simplified analysis, and a real system needs much more data and sophistication.\\\\n\\\\n```json\\\\n{\\\\n  \\\\\\\"objects\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Parked Vehicles\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Static objects; unlikely to cause immediate harm unless the ego vehicle deviates significantly from its lane.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Moving Vehicles\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Potential for collision if not properly navigated.  Proximity and speed need to be considered.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Construction Cones\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Obstacles that require avoidance to prevent damage to the vehicle.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Buildings\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Static objects; no immediate hazard.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Trees/Landscaping\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Not an immediate hazard unless the vehicle leaves the road.\\\\\\\"\\\\n    },\\\\n     {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Construction Equipment\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Large obstacle. Requires appropriate distance and avoidance.\\\\\\\"\\\\n    }\\\\n  ]\\\\n}\\\\n```\\\\n\\\\n**Important Notes:**\\\\n\\\\n* **Distance and Speed:** The judgment of \\\\\\\"harmful\\\\\\\" depends heavily on the speed of the ego vehicle (the vehicle being analyzed) and the distance to other objects.  What's harmless at low speeds can be highly dangerous at higher speeds.\\\\n* **Lane Keeping:** Staying within the lane is crucial to avoid parked cars and other obstacles.\\\\n* **Contextual Awareness:**  A real system would need to account for many more factors (traffic laws, turn signals, pedestrian presence, etc.)\\\\n* **Limited View:** The camera's field of view is limited.  Real systems often use multiple cameras, lidar, and radar for complete coverage.\\\\n\\\\n\\\\nThis JSON provides a framework. A true autonomous driving system requires a far more complex and comprehensive approach.\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"file_data\": {\n",
            "                    \"mime_type\": \"video/mp4\",\n",
            "                    \"file_uri\": \"https://generativelanguage.googleapis.com/v1beta/files/6n2eikhljlkv\"\n",
            "                }\n",
            "            },\n",
            "            {\n",
            "                \"file_data\": {\n",
            "                    \"mime_type\": \"video/mp4\",\n",
            "                    \"file_uri\": \"https://generativelanguage.googleapis.com/v1beta/files/2qg3hwh8u9r\"\n",
            "                }\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"model\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"Here's the JSON output for the provided video.  The scene includes more complex interactions requiring a more nuanced analysis than in previous examples.\\\\n\\\\n```json\\\\n{\\\\n  \\\\\\\"objects\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Pedestrian\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Direct path of the vehicle; requires immediate braking to avoid collision.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Vehicles (Cars)\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": true,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Potential for rear-end collision or other types of accidents.  Requires maintaining a safe following distance and monitoring their movements.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Overpass Structure\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Static object; no immediate risk but might affect visibility if damaged or collapsing.\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"object\\\\\\\": \\\\\\\"Buildings\\\\\\\",\\\\n      \\\\\\\"harmful\\\\\\\": false,\\\\n      \\\\\\\"reason\\\\\\\": \\\\\\\"Static; no direct hazard.\\\\\\\"\\\\n    }\\\\n  ]\\\\n}\\\\n```\\\\n\\\\n**Important Considerations for this Scene:**\\\\n\\\\n* **Pedestrian Immediacy:** The pedestrian directly in front of the vehicle is the most critical hazard and requires immediate action.\\\\n* **Following Distance:** Maintaining a safe following distance from other vehicles is crucial, especially at lower speeds where braking distances are shorter.\\\\n* **Environmental Factors:** The overpass could affect visibility, reducing reaction time.  In a real system, this needs to be accounted for.\\\\n* **Simulation Limitations:** This is a simulated environment. Real-world scenarios often have additional complexities such as varying road conditions, unexpected vehicle movements, and unpredictable pedestrian behavior.\\\\n\\\\n\\\\nThis JSON remains a simplified example.  Real-world autonomous driving systems need far more sophisticated hazard assessment algorithms and incorporate numerous sensors to ensure safety.\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"i get the code from the settings but when i ran it i got so: Uploaded file '1.mp4' as: https://generativelanguage.googleapis.com/v1beta/files/jkm6dmtvfeg8\\\\nUploaded file '2.mp4' as: https://generativelanguage.googleapis.com/v1beta/files/duvle6tej1ac\\\\nWaiting for file processing...\\\\n...all files ready\\\\n\\\\nAnalysis:\\\\nI lack the ability to access external websites or specific files online, including the URLs you provided. Therefore, I cannot analyze the videos and provide the requested JSON output.  To get the analysis you need, you would have to:\\\\n\\\\n1. **Download the videos:** Download the videos from the provided links.\\\\n2. **Use a video analysis tool:** Employ a computer vision API or a software application capable of object detection and classification.  Many such tools exist, both commercially and as open-source projects.  These tools will identify objects within the video frames.\\\\n3. **Manually assess harmfulness:** The tool's output will likely identify objects but might not inherently classify them as \\\\\\\"harmful\\\\\\\" or \\\\\\\"harmless\\\\\\\" to a car. You will need to manually review the identified objects and their context within the videos to determine their potential impact on a car (e.g., a rock is potentially harmful if it impacts the windshield, while a cloud is harmless).\\\\n4. **Create the JSON:**  Finally, you'll need to create the JSON output based on your analysis, structuring it according to your desired format.  For example, the JSON might look like this:\\\\n\\\\n\\\\n```json\\\\n{\\\\n  \\\\\\\"video1\\\\\\\": {\\\\n    \\\\\\\"objects\\\\\\\": [\\\\n      {\\\\n        \\\\\\\"object\\\\\\\": \\\\\\\"rock\\\\\\\",\\\\n        \\\\\\\"harmful\\\\\\\": true,\\\\n        \\\\\\\"reasoning\\\\\\\": \\\\\\\"Could cause damage to windshield or undercarriage if the car drives over it.\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"object\\\\\\\": \\\\\\\"tree\\\\\\\",\\\\n        \\\\\\\"harmful\\\\\\\": true,\\\\n        \\\\\\\"reasoning\\\\\\\": \\\\\\\"Could cause significant damage if the car collides with it.\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"object\\\\\\\": \\\\\\\"person\\\\\\\",\\\\n        \\\\\\\"harmful\\\\\\\": true,\\\\n        \\\\\\\"reasoning\\\\\\\": \\\\\\\"Potential for collision resulting in injury and/or car damage.\\\\\\\"\\\\n      }\\\\n    ]\\\\n  },\\\\n  \\\\\\\"video2\\\\\\\": {\\\\n    \\\\\\\"objects\\\\\\\": [\\\\n      {\\\\n        \\\\\\\"object\\\\\\\": \\\\\\\"car\\\\\\\",\\\\n        \\\\\\\"harmful\\\\\\\": false,\\\\n        \\\\\\\"reasoning\\\\\\\": \\\\\\\"Another car; potential for collision, but classified as potentially harmful only if involved in an accident.\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"object\\\\\\\": \\\\\\\"bird\\\\\\\",\\\\n        \\\\\\\"harmful\\\\\\\": false,\\\\n        \\\\\\\"reasoning\\\\\\\": \\\\\\\"Unlikely to cause any damage to the car.\\\\\\\"\\\\n      }\\\\n    ]\\\\n  }\\\\n}\\\\n```\\\\n\\\\nRemember to replace the example objects and reasoning with your actual findings from the video analysis.  The structure can be adapted to your specific needs.\\\\n\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"model\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"That's correct.  I apologize for the misunderstanding. As a large language model, I cannot directly access or process files from external URLs.  My previous responses were based on the *visual information* you provided within the prompts, not the actual video files themselves.\\\\n\\\\nThe steps you've outlined are precisely how you would need to proceed to analyze the videos and create the JSON output you desire.  You will need a computer vision tool to perform object detection and then add your own judgment on the \\\\\\\"harmful\\\\\\\" classification.\\\\n\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# import necessary modules.\n",
        "import base64\n",
        "import copy\n",
        "import json\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "try:\n",
        "    # The SDK will automatically read it from the GOOGLE_API_KEY environment variable.\n",
        "    # In Colab get the key from Colab-secrets (\"üîë\" in the left panel).\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Parse the arguments\n",
        "\n",
        "model = 'gemini-1.5-flash' # @param {isTemplate: true}\n",
        "contents_b64 = '[{"role":"model","parts":[{"file_data":{"mime_type":"video/mp4","drive_id":"1T60SWuQWx22DjUE2yp_e4zuRrHjDucUf"}}]},{"role":"user","parts":[{"text":"I want you based on these conditions (the objects that cause a change in the speed or car's direction, the objects proximity to the car, and the objects that will cause the car to stop immediately) to JUST produce a Json file that contains the object and whether it is harmful or harmless to my car\\n"}]},{"role":"model","parts":[{"text":"Here's a JSON representation of the objects detected in the video, categorized as harmful or harmless based on the provided criteria.  Note that this analysis is based on a short video clip and a limited understanding of the context. A complete autonomous driving system would require far more sophisticated analysis.  The determination of \\\"harmful\\\" is also subjective and depends on the driving scenario and speed.\\n\\n\\n```json\\n{\\n  \\\"objects\\\": [\\n    {\\n      \\\"object\\\": \\\"Vehicle (various)\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Potential collision if not appropriately navigated, proximity varies.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Construction Cones\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Obstacle requiring avoidance to prevent collision.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Construction Equipment\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Large obstacle; immediate stop required if in close proximity.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Pedestrian (partially visible)\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Potential collision if not properly avoided.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Trees/Landscaping\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Not an immediate hazard, though could be indirectly involved in an accident.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Buildings\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Static objects; no immediate hazard.\\\"\\n    }\\n  ]\\n}\\n```\\n\\n**Important Considerations:**\\n\\n* **Incomplete Information:** The video provides only limited views of the surroundings. A real-world system would need a 360-degree view, depth sensors, and more advanced algorithms.\\n* **Context is Key:** The determination of \\\"harmful\\\" is highly dependent on the speed of the car, the trajectory of other objects, and overall driving conditions.\\n* **Dynamic Situations:** The judgment of harmful vs harmless is highly time-sensitive.  Objects can quickly become dangerous depending on their movement.\\n\\nThis JSON aims to illustrate a basic structure for representing object detection and hazard assessment. A real-world application requires far more comprehensive capabilities.\\n"}]},{"role":"user","parts":[{"file_data":{"mime_type":"video/mp4","drive_id":"1nkKg-unFmfnLmZPHLG0_kxD5j1k7btAk"}}]},{"role":"user","parts":[{"text":"and this\\n"}]},{"role":"model","parts":[{"text":"Here's a JSON file representing the objects detected in the new video, categorized as harmful or harmless.  Remember that this is a simplified analysis based on a short clip and limited contextual information. A real autonomous driving system would require far more sophisticated processing.\\n\\n\\n```json\\n{\\n  \\\"objects\\\": [\\n    {\\n      \\\"object\\\": \\\"Pedestrians\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Potential collision if the vehicle does not stop or slow down appropriately.  High risk given they are crossing the street.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Vehicles (Bus, Car)\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Potential collision if not properly navigated, especially given the intersection.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Traffic Signals (Red Light)\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Requires immediate stop to avoid collision and traffic violation.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Buildings\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Static objects; no immediate hazard.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Construction (in background)\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Distant and not directly impeding the vehicle's path.\\\"\\n    }\\n  ]\\n}\\n```\\n\\n**Key Considerations:**\\n\\n* **Traffic Signals:** The red light is the most critical element.  Failure to stop poses a severe risk.\\n* **Pedestrian Priority:** Pedestrians in crosswalks have the right of way, making them high-risk objects.\\n* **Intersection Dynamics:** Intersections are inherently dangerous due to multiple moving vehicles and pedestrians.\\n* **Contextual Limitations:**  This analysis is very basic.  A production-ready system needs much more information (speed, distances, vehicle trajectories, etc.).\\n\\n\\nThis JSON should be viewed as a simplified example.  Robust object detection and hazard assessment for autonomous driving requires advanced sensor fusion, machine learning, and extensive safety protocols.\\n"}]},{"role":"user","parts":[{"file_data":{"mime_type":"video/mp4","drive_id":"1Qp9om3-hr-_gJCvGtcGRfKqOFO1y4C3p"}}]},{"role":"user","parts":[{"text":"and this"}]},{"role":"model","parts":[{"text":"Here's a JSON representation of the objects in this video clip, categorized as harmful or harmless.  Remember the caveats from previous responses: this is a simplified analysis, and a real system needs much more data and sophistication.\\n\\n```json\\n{\\n  \\\"objects\\\": [\\n    {\\n      \\\"object\\\": \\\"Parked Vehicles\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Static objects; unlikely to cause immediate harm unless the ego vehicle deviates significantly from its lane.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Moving Vehicles\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Potential for collision if not properly navigated.  Proximity and speed need to be considered.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Construction Cones\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Obstacles that require avoidance to prevent damage to the vehicle.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Buildings\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Static objects; no immediate hazard.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Trees/Landscaping\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Not an immediate hazard unless the vehicle leaves the road.\\\"\\n    },\\n     {\\n      \\\"object\\\": \\\"Construction Equipment\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Large obstacle. Requires appropriate distance and avoidance.\\\"\\n    }\\n  ]\\n}\\n```\\n\\n**Important Notes:**\\n\\n* **Distance and Speed:** The judgment of \\\"harmful\\\" depends heavily on the speed of the ego vehicle (the vehicle being analyzed) and the distance to other objects.  What's harmless at low speeds can be highly dangerous at higher speeds.\\n* **Lane Keeping:** Staying within the lane is crucial to avoid parked cars and other obstacles.\\n* **Contextual Awareness:**  A real system would need to account for many more factors (traffic laws, turn signals, pedestrian presence, etc.)\\n* **Limited View:** The camera's field of view is limited.  Real systems often use multiple cameras, lidar, and radar for complete coverage.\\n\\n\\nThis JSON provides a framework. A true autonomous driving system requires a far more complex and comprehensive approach.\\n"}]},{"role":"user","parts":[{"file_data":{"mime_type":"video/mp4","drive_id":"1e41tyrU8A_JAEdpdAFUYf_kT2oeKqWGJ"}},{"file_data":{"mime_type":"video/mp4","drive_id":"1FedMVUEiAEjD9u0O8aYivU_nzm7DvAFZ"}}]},{"role":"model","parts":[{"text":"Here's the JSON output for the provided video.  The scene includes more complex interactions requiring a more nuanced analysis than in previous examples.\\n\\n```json\\n{\\n  \\\"objects\\\": [\\n    {\\n      \\\"object\\\": \\\"Pedestrian\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Direct path of the vehicle; requires immediate braking to avoid collision.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Vehicles (Cars)\\\",\\n      \\\"harmful\\\": true,\\n      \\\"reason\\\": \\\"Potential for rear-end collision or other types of accidents.  Requires maintaining a safe following distance and monitoring their movements.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Overpass Structure\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Static object; no immediate risk but might affect visibility if damaged or collapsing.\\\"\\n    },\\n    {\\n      \\\"object\\\": \\\"Buildings\\\",\\n      \\\"harmful\\\": false,\\n      \\\"reason\\\": \\\"Static; no direct hazard.\\\"\\n    }\\n  ]\\n}\\n```\\n\\n**Important Considerations for this Scene:**\\n\\n* **Pedestrian Immediacy:** The pedestrian directly in front of the vehicle is the most critical hazard and requires immediate action.\\n* **Following Distance:** Maintaining a safe following distance from other vehicles is crucial, especially at lower speeds where braking distances are shorter.\\n* **Environmental Factors:** The overpass could affect visibility, reducing reaction time.  In a real system, this needs to be accounted for.\\n* **Simulation Limitations:** This is a simulated environment. Real-world scenarios often have additional complexities such as varying road conditions, unexpected vehicle movements, and unpredictable pedestrian behavior.\\n\\n\\nThis JSON remains a simplified example.  Real-world autonomous driving systems need far more sophisticated hazard assessment algorithms and incorporate numerous sensors to ensure safety.\\n"}]},{"role":"user","parts":[{"text":"i get the code from the settings but when i ran it i got so: Uploaded file '1.mp4' as: https://generativelanguage.googleapis.com/v1beta/files/jkm6dmtvfeg8\\nUploaded file '2.mp4' as: https://generativelanguage.googleapis.com/v1beta/files/duvle6tej1ac\\nWaiting for file processing...\\n...all files ready\\n\\nAnalysis:\\nI lack the ability to access external websites or specific files online, including the URLs you provided. Therefore, I cannot analyze the videos and provide the requested JSON output.  To get the analysis you need, you would have to:\\n\\n1. **Download the videos:** Download the videos from the provided links.\\n2. **Use a video analysis tool:** Employ a computer vision API or a software application capable of object detection and classification.  Many such tools exist, both commercially and as open-source projects.  These tools will identify objects within the video frames.\\n3. **Manually assess harmfulness:** The tool's output will likely identify objects but might not inherently classify them as \\\"harmful\\\" or \\\"harmless\\\" to a car. You will need to manually review the identified objects and their context within the videos to determine their potential impact on a car (e.g., a rock is potentially harmful if it impacts the windshield, while a cloud is harmless).\\n4. **Create the JSON:**  Finally, you'll need to create the JSON output based on your analysis, structuring it according to your desired format.  For example, the JSON might look like this:\\n\\n\\n```json\\n{\\n  \\\"video1\\\": {\\n    \\\"objects\\\": [\\n      {\\n        \\\"object\\\": \\\"rock\\\",\\n        \\\"harmful\\\": true,\\n        \\\"reasoning\\\": \\\"Could cause damage to windshield or undercarriage if the car drives over it.\\\"\\n      },\\n      {\\n        \\\"object\\\": \\\"tree\\\",\\n        \\\"harmful\\\": true,\\n        \\\"reasoning\\\": \\\"Could cause significant damage if the car collides with it.\\\"\\n      },\\n      {\\n        \\\"object\\\": \\\"person\\\",\\n        \\\"harmful\\\": true,\\n        \\\"reasoning\\\": \\\"Potential for collision resulting in injury and/or car damage.\\\"\\n      }\\n    ]\\n  },\\n  \\\"video2\\\": {\\n    \\\"objects\\\": [\\n      {\\n        \\\"object\\\": \\\"car\\\",\\n        \\\"harmful\\\": false,\\n        \\\"reasoning\\\": \\\"Another car; potential for collision, but classified as potentially harmful only if involved in an accident.\\\"\\n      },\\n      {\\n        \\\"object\\\": \\\"bird\\\",\\n        \\\"harmful\\\": false,\\n        \\\"reasoning\\\": \\\"Unlikely to cause any damage to the car.\\\"\\n      }\\n    ]\\n  }\\n}\\n```\\n\\nRemember to replace the example objects and reasoning with your actual findings from the video analysis.  The structure can be adapted to your specific needs.\\n\\n"}]},{"role":"model","parts":[{"text":"That's correct.  I apologize for the misunderstanding. As a large language model, I cannot directly access or process files from external URLs.  My previous responses were based on the *visual information* you provided within the prompts, not the actual video files themselves.\\n\\nThe steps you've outlined are precisely how you would need to proceed to analyze the videos and create the JSON output you desire.  You will need a computer vision tool to perform object detection and then add your own judgment on the \\\"harmful\\\" classification.\\n"}]}]' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MSwidG9wX3AiOjAuOTUsInRvcF9rIjo0MCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "# Convert and upload the files\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data, index):\n",
        "    \"\"\"Upload files to the Files API.\n",
        "\n",
        "    For each file, Google AI Studio either sent:\n",
        "    - a Google Drive ID,\n",
        "    - a URL,\n",
        "    - a file path, or\n",
        "    - The raw bytes (`inline_data`).\n",
        "\n",
        "    The API only understands `inline_data` or it's Files API.\n",
        "    This code, uploads files to the files API where the API can access them.\n",
        "    \"\"\"\n",
        "\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "        global drive\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        path = tempfiles / str(index)\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"üìÅ Files\" in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "\n",
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "index = 0\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data, index)\n",
        "            index += 1\n",
        "\n",
        "import json\n",
        "print(json.dumps(contents, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1b065de4-21ac-49e3-cea2-1f3e9842b4e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=stream,\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9d345e9868"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />Docs on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />More notebooks in the Cookbook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91AeeGO1ncU"
      },
      "source": [
        "## [optional] Show the conversation\n",
        "\n",
        "This section displays the conversation received from Google AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yoL3p3KPylFW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "8e459146-2984-4182-f7a6-f55a7a007574"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "name 'data' is used prior to global declaration (<ipython-input-7-659c6781f740>, line 49)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-659c6781f740>\"\u001b[0;36m, line \u001b[0;32m49\u001b[0m\n\u001b[0;31m    global data\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m name 'data' is used prior to global declaration\n"
          ]
        }
      ],
      "source": [
        "# @title Show the conversation, in colab.\n",
        "import mimetypes\n",
        "\n",
        "def show_file(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "\n",
        "    if drive_id := file_data.get(\"drive_id\", None):\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        name = path\n",
        "        # data = path.read_bytes()\n",
        "        kwargs = {\"filename\": path}\n",
        "    elif url := file_data.get(\"url\", None):\n",
        "        name = url\n",
        "        kwargs = {\"url\": url}\n",
        "        # response = requests.get(url)\n",
        "        # data = response.content\n",
        "    elif data := file_data.get(\"inline_data\", None):\n",
        "        name = None\n",
        "        kwargs = {\"data\": data}\n",
        "    elif name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files to \"\n",
        "                'Colab using the file manager (\"üìÅ Files\"in the left toolbar)'\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "        print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "        return\n",
        "\n",
        "    format = mimetypes.guess_extension(mime_type).strip(\".\")\n",
        "    if mime_type.startswith(\"image/\"):\n",
        "        image = IPython.display.Image(**kwargs, width=256)\n",
        "        IPython.display.display(image)\n",
        "        print()\n",
        "        return\n",
        "\n",
        "    if mime_type.startswith(\"audio/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Audio(**kwargs)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    if mime_type.startswith(\"video/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Video(**kwargs, mimetype=mime_type)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "\n",
        "\n",
        "for content in gais_contents:\n",
        "    if role := content.get(\"role\", None):\n",
        "        print(\"Role:\", role, \"\\n\")\n",
        "\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if text := part.get(\"text\", None):\n",
        "            print(text, \"\\n\")\n",
        "\n",
        "        elif file_data := part.get(\"file_data\", None):\n",
        "            show_file(file_data)\n",
        "\n",
        "    print(\"-\" * 80, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Set up the Gemini API key\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyBmTY_6kFWyOahCviIbQlgbkUPKJzBEzXU\"\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Specify the video file name\n",
        "video_file_name = \"1.mp4\"\n",
        "\n",
        "# Step 1: Upload the video file\n",
        "print(f\"Uploading file '{video_file_name}'...\")\n",
        "video_file = genai.upload_file(path=video_file_name, mime_type=\"video/mp4\")\n",
        "print(f\"Completed upload: {video_file.uri}\")\n",
        "\n",
        "# Step 2: Ensure the file is processed and active\n",
        "def wait_for_file_ready(file):\n",
        "    print(\"Waiting for file to be ready...\")\n",
        "    while True:\n",
        "        updated_file = genai.get_file(file.name)\n",
        "        if updated_file.state.name == \"ACTIVE\":\n",
        "            print(f\"File '{file.display_name}' is ready for processing.\")\n",
        "            break\n",
        "        elif updated_file.state.name == \"FAILED\":\n",
        "            raise Exception(f\"File processing failed: {updated_file.state}\")\n",
        "        else:\n",
        "            print(\"Processing...\", end=\"\\r\", flush=True)\n",
        "            time.sleep(10)\n",
        "\n",
        "wait_for_file_ready(video_file)\n",
        "\n",
        "# Step 3: Create a prompt for video analysis\n",
        "prompt = (\n",
        "    f\"Analyze the video at {video_file.uri} for objects. \"\n",
        "    \"Identify objects that may be harmful to a car and classify them as harmful or harmless. \"\n",
        "    \"Provide a JSON response with the analysis and reasoning.\"\n",
        ")\n",
        "\n",
        "# Step 4: Initialize the Gemini model and analyze the video\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "chat_session = model.start_chat()\n",
        "response = chat_session.send_message({\"role\": \"user\", \"parts\": [prompt]})\n",
        "\n",
        "# Step 5: Output the analysis\n",
        "print(\"Analysis JSON:\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "GIGS7I6tv6Wz",
        "outputId": "23172db9-ba29-4040-de18-0e9a7bf5e4b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file '1.mp4'...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/4zhswnlnypw4\n",
            "Waiting for file to be ready...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'time' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0ce30a628555>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mwait_for_file_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Step 3: Create a prompt for video analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0ce30a628555>\u001b[0m in \u001b[0;36mwait_for_file_ready\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mwait_for_file_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Specify the video file name\n",
        "video_file_name = \"1.mp4\"\n",
        "\n",
        "# Print a confirmation message\n",
        "print(\"Uploading file...\")\n",
        "\n",
        "# Upload the video file\n",
        "video_file = genai.upload_file(path=video_file_name)\n",
        "\n",
        "# Print the confirmation with the URI\n",
        "print(f\"Completed upload: {video_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "_DUpTAx0w190",
        "outputId": "d83e9c84-aa19-473c-81c7-f67b82a85b6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/ebhdh9z55ace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Specify the video file name\n",
        "video_file_name = \"1.mp4\"\n",
        "\n",
        "# Print a confirmation message\n",
        "print(\"Uploading file...\")\n",
        "\n",
        "# Upload the video file\n",
        "video_file = genai.upload_file(path=video_file_name)\n",
        "\n",
        "# Print the confirmation with the URI\n",
        "print(f\"Completed upload: {video_file.uri}\")\n",
        "\n",
        "# Check the upload status and wait until it's active\n",
        "while video_file.state.name == \"PROCESSING\":\n",
        "    print(\"Waiting for the file to be processed...\")\n",
        "    time.sleep(10)  # Wait for 10 seconds before checking again\n",
        "    video_file = genai.get_file(video_file.name)  # Update the video_file object\n",
        "\n",
        "if video_file.state.name == \"FAILED\":\n",
        "    raise ValueError(\"File upload failed.\")\n",
        "\n",
        "print(\"File is ready for inference.\")\n",
        "\n",
        "# Create your prompt for the video\n",
        "prompt = (\n",
        "    f\"Analyze the video at {video_file.uri} for objects. \"\n",
        "    \"Identify objects that may be harmful to a car and classify them as harmful or harmless. \"\n",
        "    \"Provide a JSON response with the analysis and reasoning.\"\n",
        ")\n",
        "# Choose the Gemini model\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "\n",
        "# Make the LLM request\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([\n",
        "    video_file,\n",
        "    prompt\n",
        "], request_options={\"timeout\": 600})\n",
        "\n",
        "# Print the response\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9UCbv5btxGi9",
        "outputId": "b92dfca7-a363-4245-cbf8-b76f1b0aac16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/ql4vzm6h8dun\n",
            "Waiting for the file to be processed...\n",
            "File is ready for inference.\n",
            "Making LLM inference request...\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"frame\": 0,\n",
            "    \"object\": \"pedestrian\",\n",
            "    \"bounding_box\": [177, 511, 196, 582],\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"A pedestrian is considered harmful to a vehicle as it can cause damage to the vehicle if struck, and vice versa.\"\n",
            "  },\n",
            "  {\n",
            "    \"frame\": 0,\n",
            "    \"object\": \"car\",\n",
            "    \"bounding_box\": [460, 523, 502, 562],\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"A car can be harmful as it poses a collision risk to the self-driving car.\"\n",
            "  },\n",
            "  {\n",
            "    \"frame\": 0,\n",
            "    \"object\": \"car\",\n",
            "    \"bounding_box\": [522, 523, 567, 560],\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"A car can be harmful as it poses a collision risk to the self-driving car.\"\n",
            "  },\n",
            "  {\n",
            "    \"frame\": 4,\n",
            "    \"object\": \"car\",\n",
            "    \"bounding_box\": [45, 553, 252, 628],\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"A car can be harmful as it poses a collision risk to the self-driving car.\"\n",
            "  },\n",
            "  {\n",
            "    \"frame\": 4,\n",
            "    \"object\": \"car\",\n",
            "    \"bounding_box\": [680, 555, 793, 633],\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"A car can be harmful as it poses a collision risk to the self-driving car.\"\n",
            "  },\n",
            "\n",
            "  {\n",
            "    \"frame\": 6,\n",
            "    \"object\": \"pedestrian\",\n",
            "    \"bounding_box\": [486, 575, 511, 653],\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"A pedestrian is considered harmful to a vehicle as it can cause damage to the vehicle if struck, and vice versa.\"\n",
            "  },\n",
            "  {\n",
            "    \"frame\": 10,\n",
            "    \"object\": \"pedestrian\",\n",
            "    \"bounding_box\": [432, 601, 472, 740],\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"A pedestrian is considered harmful to a vehicle as it can cause damage to the vehicle if struck, and vice versa.\"\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Specify the list of video file names\n",
        "video_files = [\"1.mp4\", \"2.mp4\", \"3.mp4\"]\n",
        "\n",
        "# Set up the Gemini API key\n",
        "genai.configure(api_key=\"AIzaSyBmTY_6kFWyOahCviIbQlgbkUPKJzBEzXU\")\n",
        "\n",
        "# Loop over each video file\n",
        "for video_file_name in video_files:\n",
        "    try:\n",
        "        # Step 1: Upload the video file\n",
        "        print(f\"Uploading file '{video_file_name}'...\")\n",
        "        video_file = genai.upload_file(path=video_file_name)\n",
        "\n",
        "        # Print the confirmation with the URI\n",
        "        print(f\"Completed upload: {video_file.uri}\")\n",
        "\n",
        "        # Step 2: Check the upload status and wait until it's active\n",
        "        while video_file.state.name == \"PROCESSING\":\n",
        "            print(f\"Waiting for the file '{video_file_name}' to be processed...\")\n",
        "            time.sleep(10)  # Wait for 10 seconds before checking again\n",
        "            video_file = genai.get_file(video_file.name)  # Update the video_file object\n",
        "\n",
        "        if video_file.state.name == \"FAILED\":\n",
        "            raise ValueError(f\"File upload failed for '{video_file_name}'.\")\n",
        "\n",
        "        print(f\"File '{video_file_name}' is ready for inference.\")\n",
        "\n",
        "        # Step 3: Create the prompt for the video\n",
        "        prompt = (\n",
        "            f\"Analyze the video at {video_file.uri} for objects. \"\n",
        "            \"Identify objects that may be harmful to a car and classify them as harmful or harmless. \"\n",
        "            \"Provide a JSON response with the analysis and reasoning.\"\n",
        "        )\n",
        "\n",
        "        # Step 4: Choose the Gemini model\n",
        "        model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "\n",
        "        # Step 5: Make the LLM request\n",
        "        print(f\"Making LLM inference request for '{video_file_name}'...\")\n",
        "        response = model.generate_content([video_file, prompt], request_options={\"timeout\": 600})\n",
        "\n",
        "        # Step 6: Print the response\n",
        "        print(f\"Analysis for '{video_file_name}':\")\n",
        "        print(response.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing '{video_file_name}': {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3zZLitiZyJTH",
        "outputId": "6f29ca25-c502-43ab-c3f6-da9ec45f6841"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file '1.mp4'...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/u2d7wyv71z34\n",
            "File '1.mp4' is ready for inference.\n",
            "Making LLM inference request for '1.mp4'...\n",
            "Analysis for '1.mp4':\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"time\": \"0:00\",\n",
            "    \"object\": \"pedestrian\",\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"Pedestrians can cause damage to a vehicle if struck by it.\"\n",
            "  },\n",
            "  {\n",
            "    \"time\": \"0:01\",\n",
            "    \"object\": \"cars\",\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"Cars can cause damage to another vehicle if involved in a collision.\"\n",
            "  },\n",
            "  {\n",
            "    \"time\": \"0:05\",\n",
            "    \"object\": \"pedestrian\",\n",
            "    \"classification\": \"harmful\",\n",
            "    \"reasoning\": \"Pedestrians can cause damage to a vehicle if struck by it.\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "Uploading file '2.mp4'...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/hjn4p7ea55c2\n",
            "Waiting for the file '2.mp4' to be processed...\n",
            "File '2.mp4' is ready for inference.\n",
            "Making LLM inference request for '2.mp4'...\n",
            "Analysis for '2.mp4':\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"time\": 0,\n",
            "    \"object\": \"car\",\n",
            "    \"category\": \"harmful\",\n",
            "    \"reasoning\": \"The car is moving towards the ego vehicle and may cause a collision if the ego vehicle does not stop or move.\"\n",
            "  },\n",
            "  {\n",
            "    \"time\": 0,\n",
            "    \"object\": \"car\",\n",
            "    \"category\": \"harmless\",\n",
            "    \"reasoning\": \"The car is moving away from the ego vehicle in the same direction, with sufficient distance, posing no immediate threat of collision.\"\n",
            "  },\n",
            "  {\n",
            "    \"time\": 17,\n",
            "    \"object\": \"car\",\n",
            "    \"category\": \"harmless\",\n",
            "    \"reasoning\": \"The car is moving in the same direction as the ego vehicle, farther ahead, and does not pose a threat.\"\n",
            "  },\n",
            "  {\n",
            "    \"time\": 20,\n",
            "    \"object\": \"truck\",\n",
            "    \"category\": \"harmless\",\n",
            "    \"reasoning\": \"Though large, it is far from the ego vehicle and moves in the same direction, with no signs of obstruction.\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "Uploading file '3.mp4'...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/o9x114ekr5mc\n",
            "Waiting for the file '3.mp4' to be processed...\n",
            "File '3.mp4' is ready for inference.\n",
            "Making LLM inference request for '3.mp4'...\n",
            "Analysis for '3.mp4':\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"time\": \"0:00\",\n",
            "    \"object\": \"red car\",\n",
            "    \"category\": \"harmful\",\n",
            "    \"reasoning\": \"The red car is close to the camera's vehicle and may pose a collision risk if it suddenly brakes or changes lanes.\"\n",
            "  },\n",
            "  {\n",
            "    \"time\": \"0:00\",\n",
            "    \"object\": \"black truck\",\n",
            "    \"category\": \"harmful\",\n",
            "    \"reasoning\": \"The black truck is parked, but its size and proximity to other moving vehicles may cause limited visibility.\"\n",
            "  },\n",
            "\n",
            "  {\n",
            "    \"time\": \"0:01\",\n",
            "    \"object\": \"pedestrian\",\n",
            "    \"category\": \"harmful\",\n",
            "    \"reasoning\": \"The pedestrian is crossing the road, posing a risk if the camera's vehicle doesn't yield.\"\n",
            "  },\n",
            "    {\n",
            "    \"time\": \"0:11\",\n",
            "    \"object\": \"pedestrian\",\n",
            "    \"category\": \"harmful\",\n",
            "    \"reasoning\": \"The pedestrian is crossing the road, posing a risk if the camera's vehicle doesn't yield.\"\n",
            "  },\n",
            "\n",
            " {\n",
            "    \"time\": \"0:13\",\n",
            "    \"object\": \"parked car\",\n",
            "    \"category\": \"harmless\",\n",
            "    \"reasoning\": \"The car is parked on the sidewalk and out of the driving path, posing no immediate threat.\"\n",
            "  },\n",
            "{\n",
            "    \"time\": \"0:17\",\n",
            "    \"object\": \"red car\",\n",
            "    \"category\": \"harmless\",\n",
            "    \"reasoning\": \"The red car is in oncoming traffic and traveling away, reducing risk of collision.\"\n",
            "  },\n",
            "  {\n",
            "    \"time\": \"0:18\",\n",
            "    \"object\": \"red car\",\n",
            "    \"category\": \"harmful\",\n",
            "    \"reasoning\": \"The red car approaches the camera's vehicle's lane and could cause a collision if its direction or speed suddenly changed.\"\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}